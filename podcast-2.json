{"podcast_details": {"podcast_title": "The AI Podcast", "episode_title": "Replit CEO Amjad Masad on Empowering the Next Billion Software Creators", "episode_image": "https://i1.sndcdn.com/avatars-000709444132-h3sd13-original.jpg", "episode_transcript": " Hello, and welcome to the NVIDIA AI Podcast. I'm your host, Noah Kravitz. When the hype around generative AI exploded at the beginning of this year, some folks, myself included, had visions of sitting down at our desks, speaking a voice command along the lines of, hey, computer, write an app that, you know, does everything I need to do today, and sitting back sipping coffee while the machinery did its magic. I can only speak for myself, but it hasn't totally worked out that way. At least not just yet. My hopes were renewed, however, when I saw a video today's guest posted to Twitter in late March. Amjad Masad is CEO of Replit, a San Francisco-based startup building AI-powered tools to bring the next billion software creators online. Replit, who's part of NVIDIA's Inception program, offers a platform that includes Ghostwriter, an AI-powered pair programmer, a real-time multiplayer editor for collaboration, and browser-based build, test, and deployment of code. The company is also working on Make Me an App functionality for its mobile app, which you should really see for yourself in the aforementioned Twitter video. And oh yeah, Replit also recently announced their open-source complete code model and a Series B fundraising extension that value the company at just over $1 billion. That's a lot of news for a year that's not quite half done as we record this. And no doubt, I've missed a few things, which is fine because Amjad is here to tell us all about Replit and the future of AI-powered software. Amjad Masad, welcome and thanks so much for joining the NVIDIA AI Podcast. Thanks for having me. If you would, why don't you tell the audience a little bit about how Replit came to be and what the company is all about. The company is about fundamentally reducing the friction between an idea and a software product. You know, we live in this magical world where, you know, someone can have an idea and sit in front of the computer, maybe hours and days later, they have something that did not exist before. And we think that is fundamentally a superpower. But currently the superpower is a little bit cumbersome, maybe not accessible to a lot of people. I sort of faced the problem myself back in college when I was doing computer science. I didn't have a laptop at the time and setting up the development environment for every programming language I was learning in school was really difficult and it was boring and was hard. And it really ate up a lot of our school time that we should have otherwise been programming. So I had this idea of I should be able to open a browser tab and start coding. At the time I was using Google Docs and other software, browser-based software like that. And to my surprise, nobody had built that. That was a year, maybe 2008. So naively, I started working on that. I thought, how hard could it be? Well, I got something working pretty quickly where you can just, it's a text box, you can evaluate some JavaScript code because the browser already knew how to do JavaScript. A lot of my friends really liked it and I continued working on it for a while. And then I wanted to add more languages and this is where I noticed it was going to be really, really hard. And so I started writing interpreters and JavaScript for Python, other languages I wanted to learn. And it turns out that's going to take many years, if not decades to finish. And so I put the project down, kind of banged my head against it for a few years. We had a breakthrough at the time. There was this sort of this trend of compiling different languages to JavaScript. So we were the first to, me and my friends, to compile Python to JavaScript. And we put out a demo and it went super viral. I remember at the time, the inventor of JavaScript kind of tweeted about it, Brandon Icke. And that was really the highlight of my life up to that point. And so I thought, okay, it'd be great to sort of build a business around this. I know there's going to be a lot of use cases for it. At the time I was back in Amman, Jordan, where I grew up and venture capital was not really a thing around the 2010s. And so I decided to open source everything I built and a bunch of companies started around it, specifically in the US at the time, maybe you remember, but there was this rise of the MOOCs sort of era to 2011. Remember getting an email from Peter Norvig, who was working at Udacity at the time, and he wanted to integrate our software, which was pretty cool. But the thing that piqued my interest was the startup in New York, making teaching code a lot easier. And it was Code Academy. So I joined them as the first employee as a founding engineer. They got me an O1 visa, I came to the US. And that sort of kicked off my career, working at the intersection of developer tools and coding. But it wasn't until 2016 that we actually started the business, Replit being the business. And we were in this incubation period for a long time, because, again, we were at an intersection of two things that didn't do particularly well for venture developers, namely sort of hobbyist software education and developer tools. It wasn't until GitHub's acquisition that this category was sort of validated. And so in 2018, we sort of raised money and we were off to the races. And yeah, so that's sort of the brief. And now you introduced Replit and the intro very well, but now you could really do anything. You can go from an idea and very little knowledge in coding into a startup, perhaps in a few days, all on Replit. So a couple of things I want to ask you about, and obviously the importance of AI when AI kind of started becoming a bigger part of Replit's stack, if you will, but business and technology-wise. But before that, maybe, and I'll say for the audience, but myself, I can read and write a tiny bit of code, but I'm not a developer. So maybe you could explain a little bit about the problem of setting up a development environment and what you were trying to solve initially, trying to just be able to open up a tab in a browser and start coding. What's that process like? How has it changed? And how has Replit kind of made things easier for developers? Anyone who's sort of been using software in the 90s or 2000s knows that typically desktop software is the way to use most apps. So you would go to the store, buy a CD or a floppy or whatever era you're in, and then go home, kind of install that software and use it. Later on, as the internet became more powerful, people started downloading and buying software off the internet and downloading it. And then as the browser got more powerful, we started putting these software applications in the browser. Now coding never really took that trajectory. It actually is stuck in the maybe 60s and 70s technology. So the way most coders still today are in the terminal, which is literally 60s built technologies. Brings me back to the VAX machines in high school. It's called a terminal. And the reason it's called a terminal is because it's supposed to connect to a mainframe. So developers today are using mainframe style technologies. And generally, I found it super surprising that the people who are building the tools for everyone have their tools really stuck in a really long gone era. And so the trouble with it is that software is largely fragmented. It is not fully integrated. There's a lot of different packages. There's a lot of different versions. Software engineers tend to be sort of idiosyncratic in the kind of tools that they want to use. And everyone integrates their development environments in their own way. And it becomes this thing where you have to download the software according to your taste and integrate it according to your taste. And then God forbid, you want to share that software. Now you expect the recipient of that code for them to be able to run it to have exactly the same configuration as your computer. And now we get anyone who's worked at a software company knows this idea of like it works on my machine. It works on your machine because it has the state that exactly instantiated that code. And by the way, that becomes a combinatorial explosion of the various versions of the packages, the compiler, the interpreter, all of the stuff that you're using. And so it is a really tough sort of problem. And some of it is self-inflicted. Some of it is a technology problem. And so it hasn't been solved. There hasn't been a lot of incentives to solve it. The market hasn't really rewarded solving it, partly because I think it's like a sort of a cultural problem where once you go through that pain, it's sort of like hazing or now you're part of a cult and you want other people to also experience that pain. So part of Replet's strategy has been to actually target people who are not living in this sort of Stockholm syndrome scenario where they think that pain is okay. Yeah. And so we've sort of grew with young people, with sort of hobbyists, with people who are typically not the professional engineer, although now professional engineers are looking over and saying, oh, how are all these people productive and happy? Maybe I want to be productive and happy. So tell us a little bit about the different features of the platform. Yeah. So essentially, Google Docs has been a huge inspiration. They've done an amazing job where I can send you a link and suddenly we're looking at the same documents. We're editing the same state of the document. There's this cute cursor thing that like, I know you're there and it's really fun, right? It's like software should be fun. And a lot of software today is kind of like that. Figma, obviously for designers, it'd be hard pressed to see any sort of industry without that sort of interaction. So that part is straightforward. You want to be able to go into a project and have the exact same state as other people in the project. So the same computers, the same underlying packages, the same file system. So we literally put people in the same cloud machine. So when you join a project, you're all in the same machine, editing the same thing, running the same thing. And it is a really delightful experience. And I still, like many years after we built that initial thing, I still find it like really, it gets me really giddy about it. It comes through. People can't see the video, but you're smiling as you're saying it. So you've got the collaborative environment. You just go on and you can see your teammates who, where they are in the code, in the document as well. And then you were also solving for that Stockholm syndrome, as you said, that's on my machine, but your environments, you're solving for that as well. Where, and feel free to answer this from the current time or if you want to go back sort of in the company's history and the emergence of generative AI. Talk about where AI comes in to do its magic. Yeah. So, you know, as someone who's worked on developer tools, essentially my entire career, one thing you notice, anyone who's worked with compilers or interpreters or what have you, one thing you'd notice is that building these sort of classical algorithms around parsers, abstract syntax trees, making sense of those trees, you tend to wonder whether deep learning could be helpful there, whether some statistical methods are helpful there. And it's sort of this question continued to bug me over time as I'm writing developer tools at Facebook or Yahoo or any of the other companies I've worked at. And at some point, I just decided to research the topic. I remember reading a paper, I think came out in 2012. It was called On the Naturalness of Software. And a couple of researchers have come up with this crazy idea that code is like natural language. And by the way, in retrospect, that's not surprising because humans are users of natural language, redesigned code to kind of feel natural to us. You just saved me from making a little bit of bad joke because when you said that, I kind of thought exactly what you just so eloquently described like, well, of course it's language. But right back then that seemed like a sort of foreign way to look at it. Well, what they found is that you can statistically model code in high precision manner. So, you know, before the current generation of natural language processing technologies, such as the transformer, which transformed kind of AI in natural language, we had classical methods such as n-grams. So n-grams, you could think about it as like sort of the percentage likelihood of the next token provided the previous token. And anyone who knows how transform work, sort of transformers also kind of train on this idea of next token prediction. But in classical methods, we're not taking the entire context into consideration because it's competitionally intractable. So it's called n-grams because it could be one gram, two gram, three gram, right? So depending on how much computing in storage you have. So they designed some kind of n-gram system to actually predict software and they built an autocomplete system on top of it that when married with a more deterministic approach, such as classical sort of intelligence, it actually outperformed sort of regular intelligence, such as in any ID. And that was eye opening for me. I was like, okay, you know, now like it's obvious that all this sort of progress and ML is just going to get applied to AI. Right. You know, and then there were a couple of tools coming out at a time. A lot of them were kind of primitive. But so we kept watching the space, kind of playing with it every now and then. But it wasn't until GPT-2, I think 2018, 2019, they were like, oh, like, this is the moment we've been waiting for. You know, we always knew that AI was going to be a huge part of our mission, because if you're mission to make something more accessible, automation and AI has to be part of it because that's the most natural way to interact with human beings, because that's what AI is great at is about modeling that interaction with humans. And so we, you know, we, we start prototyping around then. And, you know, it was like, it was almost there, but it wasn't exactly there. Like, you could do single line completions, you could do some cute stuff, but it didn't feel like an order of magnitude jump. It didn't even feel like a double digit percentage improvement in user experience for the developer. So, you know, we're a small team, we sort of set it, set it, set it aside, you know, but, you know, we had all that code for it and we had prototype of all things. Now 2020 GPT-3 drops. I was like, okay, now is actually now it's on because GPT-3 is just like vastly more powerful. It understands the structure of code. It can complete entire functions. You could like go to the open AI playground and write code. And it was like, it's on. Right. And so we started prototyping with it. Then we launched a couple of things, but actually open AI wasn't commercially accessible at the time. GPT-3, unlike GPT-2 was the first time they actually announced that they're going to stop open sourcing stuff, you know, open AI and are like, okay, like this is amazing, but you know, it's a closed system, how we're going to be building on top of it. It's not even commercial all the time. And so we realized that at some point we have to have our own AI and ML expertise. It's I think from your AI manifesto, that was a blog post, but also a Twitter thread that I think was from your colleague, not on your account. Yeah. But there's a quote, if we succeed in our mission years from today, experts will look back at our growth in the AI space and quote, people who are really serious about AI should make their own platform. Yeah. Why? So that quote actually is inspired by Alan K. And Alan K. told Steve Jobs famously, if you're serious about software, you have to make your own hardware. It's working out for Apple so far. Yes. The idea is like this vertical integration of the software and hardware layer nets out and superior user experiences, more reliable systems, sort of better flywheel effects of kind of the software improving the hardware and the hardware improving the software. And we think the same sort of stands for AI. And actually the same analogy sort of works. If you think about the platform layer, sort of the hardware layer, semi-commoditized, it's still very hard to build and cloud systems are incredibly difficult to run, but it's possible to do that. The AI layer is the kind of layer that sort of continues to improve over time. It sits on top of a platform. It is really the point at which the user is interacting with the system. And we think that's really where the most value accrue for AI. I think there's this race now to build all these foundation models, but we actually think that really the most valuable thing is going to be the applications and really the touch points between the AI and sort of the user. And the other thing is sort of like the data that you can collect and you can use to train your systems to get better at what the users do is incredibly valuable. If you're using an AI through an API, the company that's providing the AI for you is never sort of going to know the kind of use cases that your users are interested in. The reason these companies are producing these mega general models is because that's the best way to support every use case under the sun. Whereas, and I'm sure we're going to get into our language model in a bit, but our language model is a three billion parameter model. It's the smallest code model in the world or one of the smallest, yet it performs better than models 10 and a hundred X larger than that. And that's because we fine tuned it on our data. And our data is highly rich database on how people interact with our system. And so this is a few reasons of why you want to do the AI and the platform. There are a few other reasons that are actually specific to us, such as that we think the future of software development is one where AI is sort of like functioning, like an actual human collaborator. And you want the AI to be able to interact with other systems. And you want the AI to actually be able to like, for example, you want the AI to be able to spend money on your behalf or spend compute on your behalf. What we're calling our vision for artificial developer intelligence is the idea that you're sitting in Replet and the IDE with a coworker that's completely virtual and artificial, but you can ask it to do a high level task, such as produce an entire application or entire feature. And the AI has to go out and figure out how much compute it needs to spend on this, whether it needs to buy other tools from other services or be able to even hire other people or hire other AIs. And so we think all these pieces need to be available in order to build the best user experience there. How much of that can Replet do now? We built a lot of it already. So at Replet, we actually have sort of a native currency in the platform. It is not a crypto. It is merely a sort of a centralized ledger that we have. And we built a market on top of it. We call it bounties. So if you don't know how to code, you have an idea. You can go to bounties and post a bounty to get other people to do that code. Okay. But that was mostly experimental. What we really wanted is that sort of currency that allows you to buy compute from us, that allows you to buy services from other people, that allows you to buy labor, libraries. Just enabling commerce is going to be a very important way to coordinate humans and AIs. So we built that. We obviously have the software and compute substrate. We have a complete cloud system. You can run any sort of code in any language, any library. We're building all the different SKUs you need for compute. We're adding GPUs. We have deployments. We have databases. And with our Google partnerships, maybe we'll get into it in a bit, we're basically going to make the entirety of the cloud accessible via Replet. So I think we have all the ingredients today. I'm speaking with Amjad Massad. Amjad is the CEO of Replet. I called you a startup at the beginning. I don't know where the timeframe for when a startup becomes a non-startup begins or ends. But you've been doing this for a while. You've been working on developer tools since well before Replet. But Replet's been around for, should I say 2016, 2018? So it's been a minute before we got into the, I hate using the term hype cycle because if it was just hype, we wouldn't be here talking about it. But before the current explosion of, you mentioned GitHub getting acquired as a moment of validation for this space, and then obviously everything going on, we're talking about with GPT and LLMs and such. I want to go back in the context of what you were talking about with building the whole ecosystem and getting to a point where you've got, as a developer, you have a virtual counterpart, a colleague working with you. And that colleague isn't just auto completing a single line of code as at the beginning you were talking about, but is able to go out on your behalf and architect things and call in other resources and buy compute on your behalf. And I'm sure figure out the best sort of compute, the best bang for buck much faster and more capable than my human brain could do it and all that sort of things. And so that rolls into, you mentioned Replet's concept of ADI as opposed to AI or AGI or API is something different, but it's got those letters. But artificial developer intelligence. And then kind of going back to, I mentioned this in the intro, I took it from your mission statement, I believe, or from the website, this notion of bringing the next billion software creators online and using AI to help empower a non-developer to develop things. So let's get into that a little bit, if you would. And I'm sure there are parallels between the experienced developer on Replet and someone like me, a non-experienced developer who just says, hey, make me an app that can, I'm just thinking back to the examples I saw that can access my phone's webcam with cool filters, which is a really cool video that folks should go check out on your Twitter feed. Talk a little more about this idea. It sounds like kind of like AI agents. And I've explored that a little bit in some other contexts and just kind of generally the idea of going from a single prompt to a system to a system that has kind of higher order capabilities to figure out, okay, no one wants an app. What are the different steps I need to do? What are the ones I should go do on my own? When should I check back in and give him results, that kind of thing. Maybe in the way that makes most sense from Replet's point of view, walk us a little bit through this idea of ADI and empowering any developer to be able to create more and better and faster. So one of the most surprising things about large language models and this sort of generation of deep learning is how unreasonably important code is. And code is not just important in one capacity. It is important in a lot of different capacities. One part is the fact that they are exceptionally good at generating code. And we talked about how code can be modeled statistically and that's partly why. The other reason is actually it turns out that training on code makes LLMs powerful at every task. The open secret in the industry now is that if you want to train an LLM, you have to have a large percentage of your data mixture be code. In fact, a lot of people have speculated that GPT 3.5 was not GPT 3 based. It was based on codecs because codecs turned out it was doing better at certain reasoning benchmarks than vanilla GPT 3. I'll give you an example. By the way, when we trained our code model, we were surprised how it was like, although it was barely trained on any natural language, it was actually performing fairly well on natural language reasoning tasks. For example, there's this idea of theory of mind. Theory of mind is like Joe enters the room, puts the chocolates in the box. Jane enters the room, removes the chocolate out of the box. Where does Joe think the chocolate is? GPT 3 actually did really bad. I almost ran him at this. Did not know that, you know, it did not hold state for which. GPT 3 is like as an AI model, I'm unable to eat chocolate. Leave me alone. Basically, it just gave up. Turns out that, you know, code models actually do better at this. And one can speculate why. Maybe there's some philosophical reason. I was smiling when you first mentioned that thinking about incoherent Reddit arguments I've had with people. So, you know, if you train on that, it's not going to be as good a reasoning as if you train on code. Exactly. Exactly. So code is about reasoning, it's about logic, it's about holding state over time. Theory of mind is about holding state in a variable over time. That variable happened to be named Joe as opposed to X. We could spend this entire podcast kind of speculating as to why code makes language models smarter. But, you know, let's take it as a fact. And then, okay, that's the second reason why code is important. The third reason is how do these models interact with the larger world, right? You can have a language model and it could be fun. You know, you can go to chat.gpt and like, you know, spend hours writing emails, whatever. That's interesting, but has limited utility. How can this thing be more agentic and actually act on your behalf in the real world? Go out and buy groceries for you, go out and grab information for you. Well, it turns out the best way we have to interact with the internet and other computer systems is code. Calling an API, writing a small script to kind of go out and do something in the world. So that's sort of the third reason why code is important. The fourth reason is code allows us to audit and inspect the kind of plan that agentic large language models want to execute. There was a paper actually coming out of Nvidia recently called Voyager. They built an AI agent in Minecraft. Right. And it wasn't the first Minecraft agent. There's been a lot of like RL sort of exploration of Minecraft. The reason it was exciting is it was the way it learned was by writing code and improving code over time. So it writes a piece of code, interacts with the environment, and then it tests that code and then it improves it over time. And by the way, a human can come and like look at the all the code that the AI are in and we can like make sort of provable assumptions about what the AI is trying to do. So that allows us to audit it. It gets into the problem of alignment and controllability and serability. So that's a really good thing. So, okay, all these reasons why code is important for our alums. And so we think that part of the way to get into more general purpose agents is by having agents be incredibly powerful at software, be trained on code, and be part of the environment where there's like millions of programmers programming, interacting with these AIs. And so, you know, this will continue to get better over time. You know, a lot of other people contribute to it, but we think we're going to make significant contribution to the field as well. And at some point, we're going to get to a point where there is this collaborator where let's say if you're someone who's not interested in coding at all, you're someone who's, you know, just wants things to be done, you should be able to speak that software into existence. You should be able to give high level instructions to such an ADI and say, I want an app that and the thing that we built that you mentioned in the video is I want an app that does like that makes me a workout video, workout app that, you know, records my workout. And it goes and actually does that. It runs the code, it tests the code, it iterates on it, and then comes back to you. And it's like, here's a piece of software or here's an error. I shouldn't do it. Yeah. How far along is that? The video I mentioned was from March, recording this in June. So a couple months later, and I myself earlier this year, maybe around the February timeframe, played around with what was it called auto GPT? I think it was an agent that somebody had built and just released open source on GitHub that it was an early experiment, right? But the idea of an agent that can carry out, you know, as part of its task and it's science self more tasks and write code and all that. And it was a really cool sort of concept, but none of the code, at least for me that it wrote ever functioned as it should your video that I saw. And I know it's just a little video from a few months ago and you guys were working on all kinds of stuff. It's not in that video, but that popped out an app that popped out a workout app. There were a couple other demos. So how far along is that that project? And then kind of to, cause time is our enemy here. We could, we could talk all day if you had the time. This is fantastic, but to kind of land on a couple of more sort of product consumer facing notes, maybe talk a little bit about the status of ghostwriter, you know, and some of the other products that are available right now to folks who want to go try Replet. So that feature was fully built. We haven't launched it yet because we think we can do a lot better at it. Okay. But you know, it can, it can make useful, but limited apps. It can make a lot of toy apps. That's really fun to use it with your kid or something like that, but it, it, it can make limited, you know, applications and functionality. You know, part of the reason auto GPT does not work well and other sort of agent tech models is again, because they're using this general purpose model that, that is not particularly trained and, you know, gotten feedback over time from users and customers to get better. And again, that's the missing piece. That's why you need the platform and AI. So we think we can, we can get to somewhere better over the next year or so. So I think in a year you should be able to ask Replets mobile app for a really useful personal application and for it to be able to do it. For example, you can ask for some kind of application that helps you, that reminds you to take your medicine every few hours. And that should be like trivial to do. So these are the kinds of requests we're going to get into now for the more professional software developers and the kind of, you know, ADI that can help you there. We think we can get, get somewhere really interesting in the next six to sort of eight months where you can really ask it high level sort of prompts to add a certain feature to your application or you know, test entire parts of it and so on and so forth. And that's, that's a lower bar because if it makes an error, like you can correct it, you can sort of react to it. Whereas consumers will not be able to kind of correct AI, they will not be able to read the code. What Ghost Rider can do today is we have two products. One is the code complete product where as you're typing sort of passively, this AI is making suggestions. And what we're seeing is like, you know, 30, 40% of the suggestions that it's making you like, and most of the time kind of throw away the suggestions. That's because it's a small model. It's a low latency model and it's very generative. It's creating a lot of things and some things you like, some things you don't. You're not explicitly prompting it. It is just happening. Now there's more explicit prompting, which is the chat model. And for that we go back. Now we're using a mega model. We're using OpenAI or Google and a lot of different models. And you can sort of ask it questions such as like, what is my, what is this code is doing? And I'll go and I'll look at different pieces of code. It will trace the dependencies in the code. It will understand the context of the project and give you really intelligent answers. You hit a bug. There's a button that says that comes up sort of like Clippy, but in less annoying ways and says, Hey, like I noticed you have an error. Like, do you want help with that? And sometimes it makes suggestions that really fixes that error for you. And it's super useful. Any coder here knows that like the most frustrating thing is when you have a typo that eats an hour into your day, debugging it. These problems just went away. Yeah. And it's amazing in the past year or so these problems just, just went away. So, so we have all of that. The chat model knows everything about your code. It can generate entire files. It can transform entire files, but we're still so early. It's really fun. I suggest like anyone, even with cursory coding knowledge, go into Replet and you'll be able to make something. And it's a fun experience. It's just fun. Absolutely. Make interactive experience, but we're still very early. Very cool. I'll tell you generative. They have one of the, uh, I'm pristine outcomes of generative AI so far has been Clippy's reputation has never been better. I swear. Clippy went from like the pariah of software to, you know, now everybody's like, Oh, it's kind of like Clippy, but you know, we, uh, unfortunately we need to bring this conversation to a close in the next few minutes. Uh, but I'd be remiss not to ask you, especially given kind of the depth of the conversation we've been having and the historical stuff you've brought to the conversation, obviously that's informed Replet and your own career. Where's this all headed? You know, two years, five years, 10 years. I don't know how big your, your internal vision is, but, um, you know, what was the old expression software will eat the world. And now I keep thinking, well, AI is going to eat software, but right. Where are we going in the next, you know, however long? You know, I think, I think the future tend to be more normal in ways we don't expect and weirder in ways we don't expect. Like if you look at like 1950s, like sci-fi and people were thought about the future, they thought about jetbacks. They thought about holograms. You and I should be hanging in a hologram, you know, environment or virtual reality. They thought about flying cars. None of that happened. Uh, and it's unfortunate that most of it didn't happen. But what, what has happened is everyone is walking around with a rectangle in their pockets that has more computing power than the Apollo 11 computer. And they could, they, they, none of them predicted that maybe someone, some niche sort of thing predicted it, but like none of the major science fiction authors, not no one predicted that the kind of like sort of compute power that we have and really things that make us smarter and more productive and happier and hopefully, well, in some cases, you know, happier sort of question mark, whether social media and these things actually do make us happier, but at least more connected and, and everyone has a voice and there's a lot of these positive things. Education has gotten a lot better access to information, all this stuff. And so I think like any prediction about the future is probably going to follow the same thing. So I, I generally like don't like to make explicit predictions just kind of because of that, but here's what I'll say. I'll say that like we're entering a period where software is going to feel more alive. The thing about generative AI is that's really more, that's really super exciting is that computers have not been very good interacting with humans in the way our senses are used to interacting with the world, right? Prevision, audio, language, all these things, computers sucked at, and now computers are getting really good at it. And so I think computing is going to become more humane, more accessible, more exciting, more natural. Hopefully it'll solve some of the problems we have today with like having to stare at that like small rectangle on our pockets all the time. And maybe computing is going to be more embodied and more natural and kind of go about in a seamless way on our day. And that's the thing we're really excited about. Well, can I say I'm excited about it too, to hear you put it that way. Sounds good to me. Amjad, this has been a pleasure. It's been a fascinating conversation. And like I said, I could talk to you about this stuff all day or listen to you talk about it. But in the interest of time and giving our listeners somewhere to go on their own, if folks would like to know more, if they want to try Replet, if they want to learn more about the business vision, the technology, if you have a technical blog, where are some places folks can go online, on social media, anywhere else to find out more about Replet? If you don't know how to code, I would still recommend going to Replet. Go to Replet.com. We have on our homepage, we have this learn sort of section. And we have a course that we created for people with zero coding knowledge called 100 Days of Code. And you can like buy Ghost Rider, our AI product, and it can help you learn how to code as well. So check that out. If you want to make it a software project, but you don't know how to code, you don't have time to learn how to code, you can hire someone from our community using Bounty. You can put a couple hundred dollars on an idea and like get actually that idea. The developer on the other side is probably powered by AI and they're going to be very productive. That's all right. And then like our blog, blog.replet.com is where we write a lot about our vision or technical sort of ideas. And obviously, we're on all the social media channels and Twitter, YouTube, everywhere. And the videos I mentioned, I saw them on your Twitter feed, which is at AMASAD. I've read that, right? Excellent. Well, again, this has been great. Congratulations on all the success so far. But maybe more importantly, good luck with what you're doing in the future. Because as somebody who has always had a deep interest in hardware and software and how they work together, but somewhat limited knowledge of how to make those things myself, I for one, I'm going to be very curious to follow your progress, give Ghostwriter a try, see what I can do with it. So I'll do that to you. Yeah, thank you. And you know, this is such an honor to be here. You know, I've been in video sort of literally fanboy since since I was a kid. And it's been really awesome to see how the company sort of caught every wave of software. I obviously had the forefront of the current wave, which is really awesome. I'm with you. I've been a fan of your video for a long time too."}, "podcast_summary": "Replit is a San Francisco-based startup that is building AI-powered tools to make software development more accessible and efficient. The company offers a platform that includes Ghostwriter, an AI-powered pair programmer, a real-time multiplayer editor for collaboration, and browser-based build, test, and deployment of code. Replit is also working on a \"Make Me an App\" functionality that allows users to create mobile apps with little coding knowledge. The company recently announced an open-source complete code model and a Series B fundraising extension that values the company at over $1 billion. The CEO of Replit, Amjad Masad, discusses the company's mission to reduce friction in software development, their use of generative AI, and their vision for the future of AI-powered software. He envisions a future where AI acts as a virtual collaborator for software development, able to understand and generate code, interact with other systems, and even make decisions on behalf of the user. Replit's current products, such as Ghostwriter, are already providing useful features like code completion and error detection. The company is also working on empowering non-developers to create apps through their AI platform. Although Replit's AI capabilities are still in their early stages, they are constantly improving and aiming to make software development more accessible and enjoyable for users.", "podcast_guest": "Amjad Masad", "podcast_highlights": "Highlights from the podcast transcript include:\n\n- The company Replit aims to reduce friction between an idea and a software product, making coding more accessible and productive.\n\n- The Replit platform offers AI-powered tools such as Ghostwriter, a real-time multiplayer editor, and a browser-based build, test, and deployment of code.\n\n- Amjad Masad, CEO of Replit, explains the challenge of setting up a development environment and how Replit solves this problem by providing a cloud-based platform.\n\n- The importance of code in generative AI models and how it enhances reasoning, logic, and interaction with the larger world.\n\n- Replit's vision for Artificial Developer Intelligence (ADI) is to create a virtual collaborator that can understand high-level instructions, generate code, and act on behalf of the user in the real world.\n\n- Replit's current features include code completion suggestions and a chat model that can trace dependencies, provide intelligent answers, and help fix errors.\n\n- The future of computing is predicted to be more humane, accessible, natural, and embodied, with generative AI making software feel more alive.\n\nTo learn more about Replit, visit their website at replit.com and check out their blog at blog.replit.com. You can also follow Amjad Masad on Twitter at @amjadmasad for updates and videos about Replit's progress."}